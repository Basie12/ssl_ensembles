{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/Envs/ssl_ensembles/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/greg/Envs/ssl_ensembles/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/greg/Envs/ssl_ensembles/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/greg/Envs/ssl_ensembles/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/greg/Envs/ssl_ensembles/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cobra\n",
    "from cobra.core import Reaction\n",
    "from cobra.flux_analysis.parsimonious import add_pfba\n",
    "import pandas as pd\n",
    "# currently working with local medusa installation -- anytime changes are made to medusa, we need to run installation\n",
    "# again within the virtualenv by running setup.py\n",
    "#import medusa\n",
    "from medusa.reconstruct.expand.expand import iterative_gapfill_from_binary_phenotypes\n",
    "import medusa\n",
    "from medusa.flux_analysis import flux_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_universal_modelseed():\n",
    "    seed_rxn_table = pd.read_csv('../data/reactions_seed_20180809.tsv',sep='\\t')\n",
    "    seed_rxn_table['id'] = seed_rxn_table['id'] + '_c'\n",
    "    universal = cobra.io.load_json_model('../data/universal_mundy.json')\n",
    "    # remove any reactions from the universal that don't have \"OK\" status\n",
    "    # in modelSEED (guards against mass and charge-imbalanced reactions)\n",
    "    ok_ids = list(seed_rxn_table.loc[(seed_rxn_table['status'] == 'OK') | (seed_rxn_table['status'] == 'HB')]['id'])\n",
    "    remove_rxns = []\n",
    "    for reaction in universal.reactions:\n",
    "        if reaction.id not in ok_ids:\n",
    "            remove_rxns.append(reaction)\n",
    "    universal.remove_reactions(remove_rxns)\n",
    "    # remove metabolites from the universal that are no longer present in any\n",
    "    # reactions.\n",
    "    mets_in_reactions = []\n",
    "    for reaction in universal.reactions:\n",
    "        mets = [met.id for met in reaction.metabolites]\n",
    "        mets_in_reactions.extend(mets)\n",
    "    mets_in_reactions = set(mets_in_reactions)\n",
    "\n",
    "    mets_missing_reactions = []\n",
    "    for metabolite in universal.metabolites:\n",
    "        if metabolite.id not in mets_in_reactions:\n",
    "            mets_missing_reactions.append(metabolite)\n",
    "    universal.remove_metabolites(mets_missing_reactions)\n",
    "\n",
    "    universal.repair()\n",
    "    return universal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_universal = load_universal_modelseed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ensemble for Streptococcus mitis\n",
      "no cpd10515_e\n",
      "no cpd00268_e\n",
      "cpd11594_e was not in model, adding met and exchange reaction\n",
      "cpd01133_e was not in model, adding met and exchange reaction\n",
      "cpd00382_e was not in model, adding met and exchange reaction\n",
      "cpd03198_e was not in model, adding met and exchange reaction\n",
      "cpd00492_e was not in model, adding met and exchange reaction\n",
      "cpd00232_e was not in model, adding met and exchange reaction\n",
      "cpd19001_e was not in model, adding met and exchange reaction\n",
      "cpd00709_e was not in model, adding met and exchange reaction\n",
      "cpd00079_e was not in model, adding met and exchange reaction\n",
      "cpd00142_e was not in model, adding met and exchange reaction\n",
      "cpd00029_e was not in model, adding met and exchange reaction\n",
      "missing transporter for Dextrin\n",
      "missing transporter for N-Acetyl-D-mannosamine\n",
      "missing transporter for TRHL\n",
      "missing transporter for Sucrose\n",
      "missing transporter for Stachyose\n",
      "missing transporter for beta D-Galactose\n",
      "missing transporter for Acetate\n",
      "missing transporter for alpha-D-Glucose\n",
      "missing transporter for Neu5Ac\n",
      "missing transporter for Melitose\n",
      "missing transporter for D-Fructose\n",
      "missing transporter for D-glucose-6-phosphate\n",
      "missing transporter for LACT\n",
      "missing transporter for Maltose\n",
      "missing transporter for N-Acetyl-D-glucosamine\n",
      "missing transporter for Acetoacetate\n",
      "missing transporter for D-Mannose\n",
      "missing transporter for Melibiose\n",
      "Constraining lower bound for bio1\n",
      "starting cycle number 0\n",
      "starting cycle number 1\n",
      "starting cycle number 2\n",
      "starting cycle number 3\n",
      "starting cycle number 4\n",
      "starting cycle number 5\n",
      "starting cycle number 6\n",
      "starting cycle number 7\n",
      "starting cycle number 8\n",
      "starting cycle number 9\n",
      "starting cycle number 10\n",
      "starting cycle number 11\n",
      "starting cycle number 12\n",
      "starting cycle number 13\n",
      "starting cycle number 14\n",
      "starting cycle number 15\n",
      "starting cycle number 16\n",
      "starting cycle number 17\n",
      "starting cycle number 18\n",
      "starting cycle number 19\n",
      "starting cycle number 20\n",
      "starting cycle number 21\n",
      "starting cycle number 22\n",
      "starting cycle number 23\n",
      "starting cycle number 24\n",
      "starting cycle number 25\n",
      "starting cycle number 26\n",
      "starting cycle number 27\n",
      "starting cycle number 28\n",
      "starting cycle number 29\n"
     ]
    }
   ],
   "source": [
    "# Load the biolog composition to be used for gapfilling\n",
    "biolog_base_composition = pd.read_csv('../data/biolog_base_composition.csv',sep=',')\n",
    "biolog_base_dict = dict(zip(biolog_base_composition['ID'],\\\n",
    "                          [1000 for i in range(0,len(biolog_base_composition['ID']))]))\n",
    "# The biolog growth file has already been filtered by species that meet\n",
    "# the minimum carbon source requirement, so we can use the entire dataframe\n",
    "biolog_thresholded = pd.read_csv('../data/plata_thresholded.csv',sep='\\t',index_col=0)\n",
    "\n",
    "# get the list of ensembles already generated.\n",
    "already_generated = os.listdir('../results/ensembles/')\n",
    "# remove the .json extension to just get the name for each species\n",
    "already_generated = [s.split('.')[0] for s in already_generated]\n",
    "\n",
    "# Exclude species for which there is no feasible solution\n",
    "# using this reaction bag (identified during previous iterations\n",
    "# of this analysis)\n",
    "exclude_species = [\"Brachybacterium faecium\"]\n",
    "\n",
    "\n",
    "# Iterate over each species and generate and ensemble for each\n",
    "for species_file in os.listdir('../data/modelseed_models/'): \n",
    "    \n",
    "    # Load the species model. only continue if the species is in the filtered\n",
    "    # biolog dataframe (i.e. it met our filtering criteria)\n",
    "    species_name = species_file.split('.')[0]\n",
    "    if (species_name in biolog_thresholded.index) and (\n",
    "        species_name not in already_generated) and (\n",
    "        species_name not in exclude_species):\n",
    "        print(\"Building ensemble for \" + species_name)\n",
    "        model = cobra.io.load_json_model('../data/modelseed_models/' + species_file)\n",
    "\n",
    "        # extract the biolog conditions for the model of interest\n",
    "        mod_pheno = biolog_thresholded.loc[species_name]\n",
    "        mod_pheno = list(mod_pheno[mod_pheno == True].index)\n",
    "\n",
    "        # generate a fresh universal for each species\n",
    "        universal = master_universal.copy()\n",
    "\n",
    "        # check for biolog base components in the model. Add exchange reactions\n",
    "        # if none exist and add the metabolite to the model if it does not\n",
    "        # already exist\n",
    "        add_mets = []\n",
    "        add_exchanges = []\n",
    "        for met in list(biolog_base_dict.keys()):\n",
    "            try:\n",
    "                model.metabolites.get_by_id(met)\n",
    "            except:\n",
    "                print('no '+met)\n",
    "                add_met = universal.metabolites.get_by_id(met).copy()\n",
    "                add_mets.append(add_met)\n",
    "\n",
    "        model.add_metabolites(add_mets)\n",
    "\n",
    "        for met in list(biolog_base_dict.keys()):\n",
    "            # Search for exchange reactions\n",
    "            try:\n",
    "                model.reactions.get_by_id('EX_'+met)\n",
    "            except:\n",
    "                add_met = model.metabolites.get_by_id(met)\n",
    "                ex_rxn = Reaction('EX_' + met)\n",
    "                ex_rxn.name = \"Exchange reaction for \" + met\n",
    "                ex_rxn.lower_bound = -1000\n",
    "                ex_rxn.upper_bound = 1000\n",
    "                ex_rxn.add_metabolites({add_met:-1})\n",
    "                add_exchanges.append(ex_rxn)\n",
    "\n",
    "        model.add_reactions(add_exchanges)\n",
    "\n",
    "        # Find metabolites from the biolog data that are missing in the model\n",
    "        # and add them from the universal\n",
    "        missing_mets = []\n",
    "        missing_exchanges = []\n",
    "        media_dicts = {}\n",
    "        for met_id in mod_pheno:\n",
    "            try:\n",
    "                model.metabolites.get_by_id(met_id)\n",
    "            except:\n",
    "                print(met_id + \" was not in model, adding met and exchange reaction\")\n",
    "                met = universal.metabolites.get_by_id(met_id).copy()\n",
    "                missing_mets.append(met)\n",
    "                ex_rxn = Reaction('EX_' + met_id)\n",
    "                ex_rxn.name = \"Exchange reaction for \" + met_id\n",
    "                ex_rxn.lower_bound = -1000\n",
    "                ex_rxn.upper_bound = 1000\n",
    "                ex_rxn.add_metabolites({met:-1})\n",
    "                missing_exchanges.append(ex_rxn)\n",
    "            media_dicts[met_id] = biolog_base_dict.copy()\n",
    "            media_dicts[met_id] = {'EX_'+k:v for k,v in media_dicts[met_id].items()}\n",
    "            media_dicts[met_id]['EX_'+met_id] = 1000\n",
    "        model.add_metabolites(missing_mets)\n",
    "        model.add_reactions(missing_exchanges)\n",
    "\n",
    "        # identify transporters for each biolog component in the universal model\n",
    "        # and pick one that will enable transport in the gapfilling problem.\n",
    "        transporters_in_universal = [rxn for rxn in universal.reactions if len(rxn.compartments)>1]\n",
    "        for met in media_dicts.keys():\n",
    "            metabolite = model.metabolites.get_by_id(met)\n",
    "            base_met_id = met.split('_')[0]\n",
    "            rxns_with_metabolite = metabolite.reactions\n",
    "            transport = False\n",
    "            for rxn in rxns_with_metabolite:\n",
    "                metabolites = [met_in_rxn.id for met_in_rxn in rxn.metabolites]\n",
    "                if (base_met_id+'_e' in metabolites and base_met_id+'_c' in metabolites):\n",
    "                    transport = True\n",
    "\n",
    "            pick_transporter = {}\n",
    "            if not transport:\n",
    "                print(\"missing transporter for \" + metabolite.name)\n",
    "                for rxn in transporters_in_universal:\n",
    "                    metabolites = [met_in_rxn.id for met_in_rxn in rxn.metabolites]\n",
    "                    if (base_met_id+'_e' in metabolites and base_met_id+'_c' in metabolites):\n",
    "                        pick_transporter[met] = rxn.id\n",
    "\n",
    "        # Add the transporters to the model\n",
    "        transporters_to_add = list(pick_transporter.values())\n",
    "        transporter_list = []\n",
    "        for rxn in transporters_to_add:\n",
    "            transporter_list.append(universal.reactions.get_by_id(rxn).copy())\n",
    "        model.add_reactions(transporter_list)\n",
    "\n",
    "        # remove the added transporters from the universal model\n",
    "        universal.remove_reactions([universal.reactions.get_by_id(rxn) for rxn in transporters_to_add])\n",
    "\n",
    "        # generate the ensemble for this species\n",
    "        num_cycles = 100\n",
    "        lower_bound = 0.05\n",
    "        ensemble = iterative_gapfill_from_binary_phenotypes(\\\n",
    "                                         model,\\\n",
    "                                         universal,\\\n",
    "                                         media_dicts,\\\n",
    "                                         num_cycles,\\\n",
    "                                         lower_bound=lower_bound,\\\n",
    "                                         inclusion_threshold=1E-11,\\\n",
    "                                         exchange_reactions=False,\\\n",
    "                                         demand_reactions=False,\\\n",
    "                                         exchange_prefix='EX')\n",
    "\n",
    "        # save the ensemble by pickling it\n",
    "        ensemble.to_pickle('../results/ensembles/'+species_name+'.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_rxns = [rxn for rxn in ensemble.base_model.reactions \\\n",
    "                        if rxn.id.startswith('EX_')]\n",
    "for source in media_dicts.keys():\n",
    "    # close all exchange reactions\n",
    "    for rxn in ex_rxns:\n",
    "        rxn.lower_bound = 0\n",
    "    #ensemble.base_model.medium = media_dicts[source]\n",
    "    for ex_rxn in media_dicts[source].keys():\n",
    "                    ensemble.base_model.reactions.get_by_id(ex_rxn).lower_bound = \\\n",
    "                        -1.0*media_dicts[source][ex_rxn]\n",
    "                    ensemble.base_model.reactions.get_by_id(ex_rxn).upper_bound = \\\n",
    "                        1.0*media_dicts[source][ex_rxn]\n",
    "    for member in ensemble.members:\n",
    "        ensemble.set_state(member)\n",
    "        # member should produce the minimum amount of required biomass\n",
    "        # flux or more\n",
    "        if ensemble.base_model.optimize().f > 0.001:\n",
    "            print(member.id,source)\n",
    "        else:\n",
    "            print(\"no growth for \",member.id,source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_ensembles",
   "language": "python",
   "name": "ssl_ensembles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
